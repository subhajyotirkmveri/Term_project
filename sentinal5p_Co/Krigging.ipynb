{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d5d6ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pykrige in /home/sysadm/anaconda3/lib/python3.11/site-packages (1.7.1)\n",
      "Requirement already satisfied: numpy<2,>=1.14.5 in /home/sysadm/anaconda3/lib/python3.11/site-packages (from pykrige) (1.24.3)\n",
      "Requirement already satisfied: scipy<2,>=1.1.0 in /home/sysadm/anaconda3/lib/python3.11/site-packages (from pykrige) (1.10.1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "!pip install pykrige"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4fe50826",
   "metadata": {},
   "source": [
    "delhi = pd.read_csv(\"/home/sysadm/Downloads/sentinal5p_O3/Chosen_state_sep_merge_sentinel5p_O3/Delhi_sep_O3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04321468",
   "metadata": {},
   "outputs": [],
   "source": [
    "delhi"
   ]
  },
  {
   "cell_type": "raw",
   "id": "34e9317e",
   "metadata": {},
   "source": [
    "delhi.columns.tolist()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f951be3",
   "metadata": {},
   "source": [
    "date_column = delhi.columns.tolist()[2:]\n",
    "date_column"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1008cb24",
   "metadata": {},
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8202f64f",
   "metadata": {},
   "source": [
    "# Create a DataFrame with only latitude, longitude, and the specified date column\n",
    "df1 = delhi[['latitude', 'longitude', '2023-09-21']]\n",
    "\n",
    "# Create a DataFrame with latitude and longitude where the specified date column's values are NaN\n",
    "nan_locations_df = df1[df1['2023-09-21'].isna()][['latitude', 'longitude']]\n",
    "nan_locations_df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7b0f44b9",
   "metadata": {},
   "source": [
    "# Create a DataFrame with latitude, longitude, and the specified date column excluding NaN values\n",
    "pollutant_df = df1.dropna(subset=['2023-09-21'])[['latitude', 'longitude', '2023-09-21']]\n",
    "pollutant_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35f242a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pykrige.ok import OrdinaryKriging\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "629f4397",
   "metadata": {},
   "source": [
    "# Prepare the data for Ordinary Kriging\n",
    "lons = np.array(pollutant_df['longitude'])\n",
    "lats = np.array(pollutant_df['latitude'])\n",
    "zdata = np.array(pollutant_df['2023-09-21'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a525498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlags=20"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3e65ea3f",
   "metadata": {},
   "source": [
    "# Perform Ordinary Kriging\n",
    "OK = OrdinaryKriging(lons, lats, zdata, variogram_model='linear', verbose=True, enable_plotting=False, nlags=nlags)\n",
    "grid_lon = np.array(nan_locations_df[\"longitude\"])\n",
    "grid_lat = np.array(nan_locations_df[\"latitude\"])\n",
    "z1, ss1 = OK.execute('grid', grid_lon, grid_lat)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "35c9a318",
   "metadata": {},
   "source": [
    "nan_locations_df['2023-09-21'] = z1[0]\n",
    "nan_locations_df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7fe36f66",
   "metadata": {},
   "source": [
    "# Merge the two DataFrames based on their indices\n",
    "merged_df = pd.concat([pollutant_df, nan_locations_df], ignore_index=False)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6bfd21db",
   "metadata": {},
   "source": [
    "# Sort the DataFrame by ascending index\n",
    "merged_df = merged_df.sort_index(ascending=True)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5caa17",
   "metadata": {},
   "source": [
    "#Get the list of columns that have NaN values\n",
    "columns_with_nan = delhi.columns[delhi.isna().any()].tolist()\n",
    "columns_with_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdd57814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "import numpy as np\n",
    "\n",
    "def estimate_pollutant(df, date_column, nlags=20):\n",
    "    # Create a DataFrame with only latitude, longitude, and the specified date column\n",
    "    df1 = df[['longitude', 'latitude', date_column]]\n",
    "\n",
    "    # Create a DataFrame with latitude and longitude where the specified date column's values are NaN\n",
    "    nan_locations_df = df1[df1[date_column].isna()][['longitude', 'latitude']]\n",
    "\n",
    "    # Create a DataFrame with latitude, longitude, and the specified date column excluding NaN values\n",
    "    pollutant_df = df1.dropna(subset=[date_column])[['longitude', 'latitude', date_column]]\n",
    "\n",
    "    # Prepare the data for Ordinary Kriging\n",
    "    lons = np.array(pollutant_df['longitude'])\n",
    "    lats = np.array(pollutant_df['latitude'])\n",
    "    zdata = np.array(pollutant_df[date_column])\n",
    "\n",
    "    # Perform Ordinary Kriging\n",
    "    OK = OrdinaryKriging(lons, lats, zdata, variogram_model='linear', verbose=True, enable_plotting=False, nlags=nlags)\n",
    "    grid_lon = np.array(nan_locations_df[\"longitude\"])\n",
    "    grid_lat = np.array(nan_locations_df[\"latitude\"])\n",
    "    z1, ss1 = OK.execute('grid', grid_lon, grid_lat)\n",
    "\n",
    "    # Fill in NaN values in the specified date column with the interpolated values\n",
    "    nan_locations_df[date_column] = z1[0]\n",
    "\n",
    "    # Merge the two DataFrames based on their indices\n",
    "    merged_df = pd.concat([pollutant_df, nan_locations_df], ignore_index=False)\n",
    "\n",
    "    # Sort the DataFrame by ascending index\n",
    "    merged_df = merged_df.sort_index(ascending=True)\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "71794918",
   "metadata": {},
   "source": [
    "After_krigging_2023_sep_sentinal5p_Co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeee033a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting data for anisotropy...\n",
      "Initializing variogram model...\n",
      "Coordinates type: 'euclidean' \n",
      "\n",
      "Using 'linear' Variogram Model\n",
      "Slope: 4.3374039820812165e-06\n",
      "Nugget: 7.171990892976116e-06 \n",
      "\n",
      "Calculating statistics on variogram model fit...\n",
      "Executing Ordinary Kriging...\n",
      "\n",
      "Adjusting data for anisotropy...\n",
      "Initializing variogram model...\n",
      "Coordinates type: 'euclidean' \n",
      "\n",
      "Using 'linear' Variogram Model\n",
      "Slope: 7.033567795649457e-06\n",
      "Nugget: 1.8700388140737386e-05 \n",
      "\n",
      "Calculating statistics on variogram model fit...\n",
      "Executing Ordinary Kriging...\n",
      "\n",
      "Adjusting data for anisotropy...\n",
      "Initializing variogram model...\n",
      "Coordinates type: 'euclidean' \n",
      "\n",
      "Using 'linear' Variogram Model\n",
      "Slope: 6.586362838123647e-05\n",
      "Nugget: 3.2722573031145425e-05 \n",
      "\n",
      "Calculating statistics on variogram model fit...\n",
      "Executing Ordinary Kriging...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df should be the DataFrame with columns containing NaN values\n",
    "df = pd.read_csv(\"/home/sysadm/Downloads/sentinal5p_Co/Chosen_state_2023_sep_merge_sentinel5p_Co/Delhi_2023_sep_Co.csv\")\n",
    "\n",
    "# Get the list of columns that have NaN values\n",
    "columns_with_nan = df.columns[df.isna().any()].tolist()\n",
    "\n",
    "# Create an empty dictionary to store the estimated AOD DataFrames\n",
    "estimated_data = {}\n",
    "\n",
    "# Iterate through the columns with NaN values and apply estimate_aod\n",
    "for date_column in columns_with_nan:\n",
    "    estimated_data[date_column] = estimate_pollutant(df, date_column)\n",
    "\n",
    "# Create a list of columns to keep in the estimated_df\n",
    "columns_to_keep = ['longitude', 'latitude'] + columns_with_nan\n",
    "\n",
    "# Select only the desired columns from the estimated_df\n",
    "estimated_df = pd.concat([estimated_data[date_column] for date_column in columns_with_nan], axis=1)\n",
    "estimated_df = estimated_df[columns_to_keep]\n",
    "\n",
    "# Drop the duplicate 'latitude' and 'longitude' columns\n",
    "estimated_df = estimated_df.loc[:,~estimated_df.columns.duplicated()]\n",
    "\n",
    "# Create a DataFrame 'original_df' containing the original columns without NaN values\n",
    "original_columns = df.columns.difference(columns_with_nan).tolist()\n",
    "original_df = df[original_columns]\n",
    "# Merge the estimated_df and original_df based on 'latitude' and 'longitude'\n",
    "result_df = original_df.merge(estimated_df, on=['longitude', 'latitude'], how = 'inner')\n",
    "result_df.to_csv(\"/home/sysadm/Downloads/sentinal5p_Co/After_krigging_2023_sep_sentinal5p_Co/Delhi_2023_sep_Co_final.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "75df51e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>2023-09-01</th>\n",
       "      <th>2023-09-02</th>\n",
       "      <th>2023-09-03</th>\n",
       "      <th>2023-09-04</th>\n",
       "      <th>2023-09-05</th>\n",
       "      <th>2023-09-06</th>\n",
       "      <th>2023-09-07</th>\n",
       "      <th>2023-09-08</th>\n",
       "      <th>...</th>\n",
       "      <th>2023-09-20</th>\n",
       "      <th>2023-09-21</th>\n",
       "      <th>2023-09-22</th>\n",
       "      <th>2023-09-23</th>\n",
       "      <th>2023-09-24</th>\n",
       "      <th>2023-09-25</th>\n",
       "      <th>2023-09-26</th>\n",
       "      <th>2023-09-27</th>\n",
       "      <th>2023-09-28</th>\n",
       "      <th>2023-09-29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.551</td>\n",
       "      <td>76.849</td>\n",
       "      <td>0.120806</td>\n",
       "      <td>0.138337</td>\n",
       "      <td>0.121830</td>\n",
       "      <td>0.125714</td>\n",
       "      <td>0.124514</td>\n",
       "      <td>0.131611</td>\n",
       "      <td>0.130002</td>\n",
       "      <td>0.133719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116448</td>\n",
       "      <td>0.124113</td>\n",
       "      <td>0.128183</td>\n",
       "      <td>0.117908</td>\n",
       "      <td>0.126800</td>\n",
       "      <td>0.129408</td>\n",
       "      <td>0.124271</td>\n",
       "      <td>0.125626</td>\n",
       "      <td>0.122071</td>\n",
       "      <td>0.133300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.561</td>\n",
       "      <td>76.849</td>\n",
       "      <td>0.123113</td>\n",
       "      <td>0.137685</td>\n",
       "      <td>0.122348</td>\n",
       "      <td>0.126087</td>\n",
       "      <td>0.132372</td>\n",
       "      <td>0.128111</td>\n",
       "      <td>0.129450</td>\n",
       "      <td>0.134803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118284</td>\n",
       "      <td>0.120593</td>\n",
       "      <td>0.115197</td>\n",
       "      <td>0.125402</td>\n",
       "      <td>0.129639</td>\n",
       "      <td>0.130577</td>\n",
       "      <td>0.124705</td>\n",
       "      <td>0.125119</td>\n",
       "      <td>0.123917</td>\n",
       "      <td>0.127497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.571</td>\n",
       "      <td>76.849</td>\n",
       "      <td>0.119602</td>\n",
       "      <td>0.138337</td>\n",
       "      <td>0.124811</td>\n",
       "      <td>0.122651</td>\n",
       "      <td>0.126359</td>\n",
       "      <td>0.138333</td>\n",
       "      <td>0.138329</td>\n",
       "      <td>0.135462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119477</td>\n",
       "      <td>0.124305</td>\n",
       "      <td>0.127623</td>\n",
       "      <td>0.114613</td>\n",
       "      <td>0.126278</td>\n",
       "      <td>0.127863</td>\n",
       "      <td>0.121576</td>\n",
       "      <td>0.137131</td>\n",
       "      <td>0.122933</td>\n",
       "      <td>0.126219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.580</td>\n",
       "      <td>76.849</td>\n",
       "      <td>0.143472</td>\n",
       "      <td>0.138337</td>\n",
       "      <td>0.126294</td>\n",
       "      <td>0.123821</td>\n",
       "      <td>0.127240</td>\n",
       "      <td>0.126820</td>\n",
       "      <td>0.137157</td>\n",
       "      <td>0.135462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127097</td>\n",
       "      <td>0.120813</td>\n",
       "      <td>0.137923</td>\n",
       "      <td>0.113922</td>\n",
       "      <td>0.127896</td>\n",
       "      <td>0.126723</td>\n",
       "      <td>0.128667</td>\n",
       "      <td>0.135450</td>\n",
       "      <td>0.124115</td>\n",
       "      <td>0.135560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.551</td>\n",
       "      <td>76.860</td>\n",
       "      <td>0.120626</td>\n",
       "      <td>0.135761</td>\n",
       "      <td>0.124279</td>\n",
       "      <td>0.122046</td>\n",
       "      <td>0.129242</td>\n",
       "      <td>0.131650</td>\n",
       "      <td>0.122101</td>\n",
       "      <td>0.122350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113653</td>\n",
       "      <td>0.122268</td>\n",
       "      <td>0.127811</td>\n",
       "      <td>0.114778</td>\n",
       "      <td>0.119219</td>\n",
       "      <td>0.126112</td>\n",
       "      <td>0.125284</td>\n",
       "      <td>0.126075</td>\n",
       "      <td>0.123255</td>\n",
       "      <td>0.122441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>28.688</td>\n",
       "      <td>77.327</td>\n",
       "      <td>0.126005</td>\n",
       "      <td>0.135732</td>\n",
       "      <td>0.131573</td>\n",
       "      <td>0.128185</td>\n",
       "      <td>0.129889</td>\n",
       "      <td>0.129930</td>\n",
       "      <td>0.134419</td>\n",
       "      <td>0.115280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116320</td>\n",
       "      <td>0.126775</td>\n",
       "      <td>0.112370</td>\n",
       "      <td>0.121682</td>\n",
       "      <td>0.134373</td>\n",
       "      <td>0.129551</td>\n",
       "      <td>0.126508</td>\n",
       "      <td>0.135783</td>\n",
       "      <td>0.118817</td>\n",
       "      <td>0.131802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>28.512</td>\n",
       "      <td>77.337</td>\n",
       "      <td>0.122849</td>\n",
       "      <td>0.133906</td>\n",
       "      <td>0.124334</td>\n",
       "      <td>0.125453</td>\n",
       "      <td>0.128707</td>\n",
       "      <td>0.127801</td>\n",
       "      <td>0.132237</td>\n",
       "      <td>0.139142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116132</td>\n",
       "      <td>0.123082</td>\n",
       "      <td>0.126620</td>\n",
       "      <td>0.119282</td>\n",
       "      <td>0.129121</td>\n",
       "      <td>0.119854</td>\n",
       "      <td>0.123538</td>\n",
       "      <td>0.137503</td>\n",
       "      <td>0.124085</td>\n",
       "      <td>0.128500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>28.522</td>\n",
       "      <td>77.337</td>\n",
       "      <td>0.120734</td>\n",
       "      <td>0.159084</td>\n",
       "      <td>0.124543</td>\n",
       "      <td>0.128229</td>\n",
       "      <td>0.128339</td>\n",
       "      <td>0.128059</td>\n",
       "      <td>0.130902</td>\n",
       "      <td>0.135073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117879</td>\n",
       "      <td>0.124561</td>\n",
       "      <td>0.132376</td>\n",
       "      <td>0.117276</td>\n",
       "      <td>0.123837</td>\n",
       "      <td>0.120341</td>\n",
       "      <td>0.125068</td>\n",
       "      <td>0.136494</td>\n",
       "      <td>0.122596</td>\n",
       "      <td>0.137517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>28.610</td>\n",
       "      <td>77.337</td>\n",
       "      <td>0.119194</td>\n",
       "      <td>0.137661</td>\n",
       "      <td>0.126031</td>\n",
       "      <td>0.121886</td>\n",
       "      <td>0.129947</td>\n",
       "      <td>0.131101</td>\n",
       "      <td>0.130902</td>\n",
       "      <td>0.118528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118249</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>0.129906</td>\n",
       "      <td>0.114437</td>\n",
       "      <td>0.124167</td>\n",
       "      <td>0.120333</td>\n",
       "      <td>0.121093</td>\n",
       "      <td>0.126896</td>\n",
       "      <td>0.119142</td>\n",
       "      <td>0.123108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>28.619</td>\n",
       "      <td>77.337</td>\n",
       "      <td>0.121839</td>\n",
       "      <td>0.133713</td>\n",
       "      <td>0.126404</td>\n",
       "      <td>0.123999</td>\n",
       "      <td>0.129595</td>\n",
       "      <td>0.130099</td>\n",
       "      <td>0.136435</td>\n",
       "      <td>0.140121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120002</td>\n",
       "      <td>0.123867</td>\n",
       "      <td>0.132025</td>\n",
       "      <td>0.119433</td>\n",
       "      <td>0.127008</td>\n",
       "      <td>0.130074</td>\n",
       "      <td>0.124055</td>\n",
       "      <td>0.118751</td>\n",
       "      <td>0.126091</td>\n",
       "      <td>0.125808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1350 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      latitude  longitude  2023-09-01  2023-09-02  2023-09-03  2023-09-04  \\\n",
       "0       28.551     76.849    0.120806    0.138337    0.121830    0.125714   \n",
       "1       28.561     76.849    0.123113    0.137685    0.122348    0.126087   \n",
       "2       28.571     76.849    0.119602    0.138337    0.124811    0.122651   \n",
       "3       28.580     76.849    0.143472    0.138337    0.126294    0.123821   \n",
       "4       28.551     76.860    0.120626    0.135761    0.124279    0.122046   \n",
       "...        ...        ...         ...         ...         ...         ...   \n",
       "1345    28.688     77.327    0.126005    0.135732    0.131573    0.128185   \n",
       "1346    28.512     77.337    0.122849    0.133906    0.124334    0.125453   \n",
       "1347    28.522     77.337    0.120734    0.159084    0.124543    0.128229   \n",
       "1348    28.610     77.337    0.119194    0.137661    0.126031    0.121886   \n",
       "1349    28.619     77.337    0.121839    0.133713    0.126404    0.123999   \n",
       "\n",
       "      2023-09-05  2023-09-06  2023-09-07  2023-09-08  ...  2023-09-20  \\\n",
       "0       0.124514    0.131611    0.130002    0.133719  ...    0.116448   \n",
       "1       0.132372    0.128111    0.129450    0.134803  ...    0.118284   \n",
       "2       0.126359    0.138333    0.138329    0.135462  ...    0.119477   \n",
       "3       0.127240    0.126820    0.137157    0.135462  ...    0.127097   \n",
       "4       0.129242    0.131650    0.122101    0.122350  ...    0.113653   \n",
       "...          ...         ...         ...         ...  ...         ...   \n",
       "1345    0.129889    0.129930    0.134419    0.115280  ...    0.116320   \n",
       "1346    0.128707    0.127801    0.132237    0.139142  ...    0.116132   \n",
       "1347    0.128339    0.128059    0.130902    0.135073  ...    0.117879   \n",
       "1348    0.129947    0.131101    0.130902    0.118528  ...    0.118249   \n",
       "1349    0.129595    0.130099    0.136435    0.140121  ...    0.120002   \n",
       "\n",
       "      2023-09-21  2023-09-22  2023-09-23  2023-09-24  2023-09-25  2023-09-26  \\\n",
       "0       0.124113    0.128183    0.117908    0.126800    0.129408    0.124271   \n",
       "1       0.120593    0.115197    0.125402    0.129639    0.130577    0.124705   \n",
       "2       0.124305    0.127623    0.114613    0.126278    0.127863    0.121576   \n",
       "3       0.120813    0.137923    0.113922    0.127896    0.126723    0.128667   \n",
       "4       0.122268    0.127811    0.114778    0.119219    0.126112    0.125284   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1345    0.126775    0.112370    0.121682    0.134373    0.129551    0.126508   \n",
       "1346    0.123082    0.126620    0.119282    0.129121    0.119854    0.123538   \n",
       "1347    0.124561    0.132376    0.117276    0.123837    0.120341    0.125068   \n",
       "1348    0.123457    0.129906    0.114437    0.124167    0.120333    0.121093   \n",
       "1349    0.123867    0.132025    0.119433    0.127008    0.130074    0.124055   \n",
       "\n",
       "      2023-09-27  2023-09-28  2023-09-29  \n",
       "0       0.125626    0.122071    0.133300  \n",
       "1       0.125119    0.123917    0.127497  \n",
       "2       0.137131    0.122933    0.126219  \n",
       "3       0.135450    0.124115    0.135560  \n",
       "4       0.126075    0.123255    0.122441  \n",
       "...          ...         ...         ...  \n",
       "1345    0.135783    0.118817    0.131802  \n",
       "1346    0.137503    0.124085    0.128500  \n",
       "1347    0.136494    0.122596    0.137517  \n",
       "1348    0.126896    0.119142    0.123108  \n",
       "1349    0.118751    0.126091    0.125808  \n",
       "\n",
       "[1350 rows x 31 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a005a641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec44e9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df should be the DataFrame with columns containing NaN values\n",
    "df = pd.read_csv(\"/home/sysadm/Downloads/sentinal5p_Co/Chosen_state_2023_sep_merge_sentinel5p_Co/WB_2023_sep_Co.csv\")\n",
    "\n",
    "# Get the list of columns that have NaN values\n",
    "columns_with_nan = df.columns[df.isna().any()].tolist()\n",
    "\n",
    "# Create an empty dictionary to store the estimated AOD DataFrames\n",
    "estimated_data = {}\n",
    "\n",
    "# Iterate through the columns with NaN values and apply estimate_aod\n",
    "for date_column in columns_with_nan:\n",
    "    estimated_data[date_column] = estimate_pollutant(df, date_column)\n",
    "\n",
    "# Create a list of columns to keep in the estimated_df\n",
    "columns_to_keep = ['longitude', 'latitude'] + columns_with_nan\n",
    "\n",
    "# Select only the desired columns from the estimated_df\n",
    "estimated_df = pd.concat([estimated_data[date_column] for date_column in columns_with_nan], axis=1)\n",
    "estimated_df = estimated_df[columns_to_keep]\n",
    "\n",
    "# Drop the duplicate 'latitude' and 'longitude' columns\n",
    "estimated_df = estimated_df.loc[:,~estimated_df.columns.duplicated()]\n",
    "\n",
    "# Create a DataFrame 'original_df' containing the original columns without NaN values\n",
    "original_columns = df.columns.difference(columns_with_nan).tolist()\n",
    "original_df = df[original_columns]\n",
    "# Merge the estimated_df and original_df based on 'latitude' and 'longitude'\n",
    "result_df = original_df.merge(estimated_df, on=['longitude', 'latitude'], how = 'inner')\n",
    "result_df.to_csv(\"/home/sysadm/Downloads/sentinal5p_Co/After_krigging_2023_sep_sentinal5p_Co/Wb_2023_sep_Co_final.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc233d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cfe361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fce4da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83541ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5553a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2169243f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
